{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LmgR1aEta_KQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TODO\n",
        "- Decide Epochs\n",
        "- GAther y predict target \n",
        "- Test submission to y predict target "
      ],
      "metadata": {
        "id": "DywSa6K6Gwb3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "hxr8bSrnVtV4"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "# data = None\n",
        "# test_data = None\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
        "#     for filename in filenames:\n",
        "#         path = os.path.join(dirname, filename)\n",
        "#         if filename == 'train.csv':\n",
        "#             data = pd.read_csv(path)\n",
        "#         if filename == 'test.csv':\n",
        "#             test_data = pd.read_csv(path)\n",
        "#         if filename == 'store.csv':\n",
        "#             store_data = pd.read_csv(path)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive #mounting to drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Reading Zip\n",
        "from zipfile import ZipFile\n",
        "file_name = '/content/drive/My Drive/CE889/Group_Assignment/rossmann-store-sales.zip' \n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    zip.printdir()\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "\n",
        "store_data = pd.read_csv('store.csv')\n",
        "\n",
        "#Assigning data set to df\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "#Assigning Test data to df\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw2Tnh1lVyk2",
        "outputId": "a59bafef-8ee5-4c25-f48a-b3a1a46e274b"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File Name                                             Modified             Size\n",
            "sample_submission.csv                          2019-12-11 03:57:00       317611\n",
            "store.csv                                      2019-12-11 03:57:00        45010\n",
            "test.csv                                       2019-12-11 03:57:00      1427425\n",
            "train.csv                                      2019-12-11 03:57:02     38057952\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join train set and store set, test set and store set, inner refers to using the common keys\n",
        "# on refers to the label\n",
        "new_train = data.merge(store_data, how='inner', on='Store')\n",
        "new_test = test_data.merge(store_data, how='inner', on='Store')"
      ],
      "metadata": {
        "id": "RPDP-i3aV0Zf"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train['Date'] = pd.to_datetime(new_train['Date'])\n",
        "new_train['Year'] = new_train.Date.dt.year\n",
        "new_train['Month'] = new_train.Date.dt.month\n",
        "new_train['Day'] = new_train.Date.dt.day\n",
        "\n",
        "new_test['Date'] = pd.to_datetime(new_test['Date'])\n",
        "new_test['Year'] = new_train.Date.dt.year\n",
        "new_test['Month'] = new_test.Date.dt.month\n",
        "new_test['Day'] = new_test.Date.dt.day"
      ],
      "metadata": {
        "id": "KBPXpLaXV1-j"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train[\"CompetitionDistance\"]=new_train[\"CompetitionDistance\"].fillna(99999)\n",
        "new_test[\"CompetitionDistance\"]=new_test[\"CompetitionDistance\"].fillna(99999)"
      ],
      "metadata": {
        "id": "gnT3jJKUV3oi"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # convert assortment and storetype and stateholiday in training data to int\n",
        "cleanup = {\"Assortment\": {\"a\":0, \"b\":1, \"c\":2}}\n",
        "new_train.replace(cleanup, inplace=True)\n",
        "new_train['Assortment'] = new_train['Assortment'].astype(int)\n",
        "\n",
        "cleanup2 = {\"StoreType\": {\"a\":0, \"b\":1, \"c\":2, \"d\":3}}\n",
        "new_train.replace(cleanup2, inplace=True)\n",
        "new_train['StoreType'] = new_train['StoreType'].astype(int)\n",
        "\n",
        "cleanup3 = {\"StateHoliday\": {\"a\":0, \"b\":1, \"c\":2}}\n",
        "new_train.replace(cleanup3, inplace=True)\n",
        "new_train['StateHoliday'] = new_train['StateHoliday'].astype(int)"
      ],
      "metadata": {
        "id": "wY9jQvhNV5ao"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # convert assortment and storetype in testing data to int\n",
        "cleanup = {\"Assortment\": {\"a\":0, \"b\":1, \"c\":2}}\n",
        "new_test.replace(cleanup, inplace=True)\n",
        "new_test['Assortment'] = new_test['Assortment'].astype(int)\n",
        "\n",
        "cleanup2 = {\"StoreType\": {\"a\":0, \"b\":1, \"c\":2, \"d\":3}}\n",
        "new_test.replace(cleanup2, inplace=True)\n",
        "new_test['StoreType'] = new_test['StoreType'].astype(int)\n",
        "\n",
        "cleanup3 = {\"StateHoliday\": {\"a\":0, \"b\":1, \"c\":2}}\n",
        "new_train.replace(cleanup3, inplace=True)\n",
        "new_train['StateHoliday'] = new_train['StateHoliday'].astype(int)"
      ],
      "metadata": {
        "id": "86O9sG6GV62k"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYNFSl2SV8mj",
        "outputId": "f803485d-de5e-4198-c638-30a0765b30f7"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1017209 entries, 0 to 1017208\n",
            "Data columns (total 21 columns):\n",
            " #   Column                     Non-Null Count    Dtype         \n",
            "---  ------                     --------------    -----         \n",
            " 0   Store                      1017209 non-null  int64         \n",
            " 1   DayOfWeek                  1017209 non-null  int64         \n",
            " 2   Date                       1017209 non-null  datetime64[ns]\n",
            " 3   Sales                      1017209 non-null  int64         \n",
            " 4   Customers                  1017209 non-null  int64         \n",
            " 5   Open                       1017209 non-null  int64         \n",
            " 6   Promo                      1017209 non-null  int64         \n",
            " 7   StateHoliday               1017209 non-null  int64         \n",
            " 8   SchoolHoliday              1017209 non-null  int64         \n",
            " 9   StoreType                  1017209 non-null  int64         \n",
            " 10  Assortment                 1017209 non-null  int64         \n",
            " 11  CompetitionDistance        1017209 non-null  float64       \n",
            " 12  CompetitionOpenSinceMonth  693861 non-null   float64       \n",
            " 13  CompetitionOpenSinceYear   693861 non-null   float64       \n",
            " 14  Promo2                     1017209 non-null  int64         \n",
            " 15  Promo2SinceWeek            509178 non-null   float64       \n",
            " 16  Promo2SinceYear            509178 non-null   float64       \n",
            " 17  PromoInterval              509178 non-null   object        \n",
            " 18  Year                       1017209 non-null  int64         \n",
            " 19  Month                      1017209 non-null  int64         \n",
            " 20  Day                        1017209 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(5), int64(14), object(1)\n",
            "memory usage: 203.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Null value exists in open, fill with one, cuz stores would open except from holidays\n",
        "new_train['Open'] = new_train['Open'].fillna(1)\n",
        "new_train['Open'] = new_train['Open'].astype(int)\n",
        "\n",
        "\n",
        "new_test['Open'] = new_test['Open'].fillna(1)\n",
        "new_test['Open' ]= new_test['Open'].astype(int)"
      ],
      "metadata": {
        "id": "UaAW5KfaV-he"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # fill nan with month 0, years in the far future\n",
        "new_train['CompetitionOpenSinceMonth'].fillna(1, inplace=True)\n",
        "new_train['CompetitionOpenSinceYear'].fillna(2100, inplace=True)\n",
        "\n",
        "new_train['Promo2SinceWeek'].fillna(1, inplace=True)\n",
        "new_train['Promo2SinceYear'].fillna(2100, inplace=True)\n",
        "new_train['PromoInterval'].fillna(0, inplace=True)\n",
        "\n",
        "new_test['CompetitionOpenSinceMonth'].fillna(1, inplace=True)\n",
        "new_test['CompetitionOpenSinceYear'].fillna(2100, inplace=True)\n",
        "\n",
        "new_test['Promo2SinceWeek'].fillna(1, inplace=True)\n",
        "new_test['Promo2SinceYear'].fillna(2100, inplace=True)\n",
        "new_test['PromoInterval'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "7P3nDrlmWAOF"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # combine competition month and year and promo week year to form days\n",
        "new_train['CompetitionDays'] = 365 * (new_train['Year'] - new_train['CompetitionOpenSinceYear']) + new_train['Month'] - new_train['CompetitionOpenSinceMonth']\n",
        "\n",
        "new_train['PromoOpenDays'] = 365 * (new_train['Year'] - new_train['Promo2SinceYear']) + ((new_train['Day'] - 7 * new_train['Promo2SinceWeek']))\n",
        "\n",
        "new_test['CompetitionDays'] = 365 * (new_test['Year'] - new_test['CompetitionOpenSinceYear']) + new_test['Month'] - new_test['CompetitionOpenSinceMonth']\n",
        "\n",
        "new_test['PromoOpenDays'] = 365 * (new_test['Year'] - new_test['Promo2SinceYear']) + ((new_test['Day'] - 7 * new_test['Promo2SinceWeek']))"
      ],
      "metadata": {
        "id": "AH6XQj0pWB-F"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train.drop(columns = ['CompetitionOpenSinceMonth'], inplace = True)\n",
        "new_train.drop(columns =['CompetitionOpenSinceYear'], inplace = True)\n",
        "new_train.drop(columns =['Promo2SinceWeek'], inplace = True)\n",
        "new_train.drop(columns =['Promo2SinceYear'], inplace = True)\n",
        "new_train.drop(columns =['Date'], inplace = True)"
      ],
      "metadata": {
        "id": "MLijwvwfWDZv"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train = new_train.query('Open==1')\n",
        "new_test = new_test.query('Open==1')"
      ],
      "metadata": {
        "id": "93lAL5FyWFGm"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "\"\"\"\n",
        "new_train_plus = new_train\n",
        "columns = ['Sales', 'CompetitionDistance', 'CompetitionDays', 'PromoOpenDays', \"Customers\"]\n",
        "for col in columns:\n",
        "    max_value = np.max(new_train_plus[col])\n",
        "    min_value = np.min(new_train_plus[col])\n",
        "    new_train_plus[col] = (new_train_plus[col] - min_value) / (max_value - min_value)\n",
        "\n",
        "new_train = new_train_plus\n",
        "\"\"\"\n",
        "new_train.drop(columns=['Customers'],inplace = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs_kcNZOWJel",
        "outputId": "9453fd5c-999e-4be7-d41c-3d6b171a0b82"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzJqoElDWKVz",
        "outputId": "82682271-dc3e-4cee-c61b-56c43cb4aa57"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Store                    int64\n",
              "DayOfWeek                int64\n",
              "Sales                    int64\n",
              "Open                     int64\n",
              "Promo                    int64\n",
              "StateHoliday             int64\n",
              "SchoolHoliday            int64\n",
              "StoreType                int64\n",
              "Assortment               int64\n",
              "CompetitionDistance    float64\n",
              "Promo2                   int64\n",
              "PromoInterval           object\n",
              "Year                     int64\n",
              "Month                    int64\n",
              "Day                      int64\n",
              "CompetitionDays        float64\n",
              "PromoOpenDays          float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train = pd.get_dummies(new_train, columns = ['PromoInterval'])\n",
        "new_test = pd.get_dummies(new_test, columns = ['PromoInterval'])"
      ],
      "metadata": {
        "id": "tD0TiFbuWNQz"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEYyZAnc7MNW",
        "outputId": "ebfcf6d0-b7c6-4d0b-87d0-ad9beba7a730"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35104, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = new_train.drop([\"Sales\"], axis = 1)\n",
        "y = new_train[\"Sales\"]"
      ],
      "metadata": {
        "id": "J7aZf5C9WPFu"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "P5MFGUNfWR9F"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Scaling the data \n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(x,y)"
      ],
      "metadata": {
        "id": "h41Z4sq9WWBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf06ef5-9b53-47f9-c8ed-01c47dbad791"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.66666667, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.5       , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [1.        , 0.66666667, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [1.        , 0.5       , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [1.        , 0.33333333, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OEI8er17m9AV"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train.shape, X_test.shape, y_test.shape, y_train.shape"
      ],
      "metadata": {
        "id": "2wioERaF0bjC"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def df_to_X_y(df, window_size=5):\n",
        "#   df_as_np = df.to_numpy()\n",
        "#   X = []\n",
        "#   y = []\n",
        "#   for i in range(len(df_as_np)-window_size):\n",
        "#     row = [[a] for a in df_as_np[i:i+window_size]]\n",
        "#     X.append(row)\n",
        "#     label = df_as_np[i+window_size]\n",
        "#     y.append(label)\n",
        "#   return np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "YRSUQSwE0wD0"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WINDOW_SIZE = 5\n",
        "# X1, y1 = df_to_X_y(x, WINDOW_SIZE)\n",
        "# X1.shape, y1.shape"
      ],
      "metadata": {
        "id": "kiX7p1D-0y29"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x.shape"
      ],
      "metadata": {
        "id": "p-qE_Eplt1DT"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_timestep(i, window_size):\n",
        "  \n",
        "#       nrows = i.shape[0] - window_size + 1\n",
        "#       p,q = i.shape\n",
        "#       m,n = i.strides\n",
        "#       strided = np.lib.stride_tricks.as_strided\n",
        "#       output_X = strided(i,shape=(nrows,window_size,q),strides=(m,m,n))\n",
        "  \n",
        "#       return output_X\n",
        "# ''' \n",
        "# Reshaping an array to give it (n, n, n)\n",
        "# is necessary before feeding into a RNN\n",
        "\n",
        "# window_size --> passes in the current iteration, as well as n previous layers.\n",
        "\n",
        "# window_size is used for noisy or erroneous data, the window is used to mitigate\n",
        "\n",
        "# window_size can be defined from (1-->n)\n",
        "\n",
        "# '''\n",
        "\n",
        "# # create_timestep(input, window_size)"
      ],
      "metadata": {
        "id": "9KGuOKbXo7pv"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = create_timestep(X_train, 5)"
      ],
      "metadata": {
        "id": "g0tu-1s1vU8s"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test = create_timestep(X_test, 5)"
      ],
      "metadata": {
        "id": "v2dyub2Dycgo"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_test.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO8ZhTrZ2HmX",
        "outputId": "dad712f4-e8f9-4d63-96f5-b5a63e3e067f"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((675513, 19), (168879, 19), (168879,), (675513,))"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resizing Shape of test and train set to 3d arrays , needs to be changed depending on size of train test split and if data changes\n",
        "# The size of shapes should reflect the split data \n",
        "X_train = X_train.reshape(675513, 1, 19)\n",
        "X_test = X_test.reshape(168879, 1, 19)"
      ],
      "metadata": {
        "id": "y-BMMlYo2COF"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_test.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvhYhTfQbCTk",
        "outputId": "f863b60f-521b-466c-b9b8-b6c6b6aa9b34"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((675513, 1, 19), (168879, 1, 19), (168879,), (675513,))"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM ATTEMPT 2\n"
      ],
      "metadata": {
        "id": "eCKIO4ucbMye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer((1, 19)))\n",
        "model1.add(LSTM(64))\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(1, 'linear'))\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCkATZy9bPX2",
        "outputId": "e1a03acb-7269-40f0-a6be-854de400444d"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 64)                21504     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 520       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,033\n",
            "Trainable params: 22,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp1 = ModelCheckpoint('model1/', save_best_only=True)\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=1e-4), metrics=[RootMeanSquaredError()])"
      ],
      "metadata": {
        "id": "xWhwwKeQbMFN"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train, y_train, epochs=3, callbacks=[cp1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhDXUMylbfEE",
        "outputId": "c42a82bc-ba63-40d4-f09d-eb3276fef4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "21102/21110 [============================>.] - ETA: 0s - loss: 56257884.0000 - root_mean_squared_error: 7500.5254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21110/21110 [==============================] - 79s 4ms/step - loss: 56256960.0000 - root_mean_squared_error: 7500.4639\n",
            "Epoch 2/3\n",
            "21106/21110 [============================>.] - ETA: 0s - loss: 47289180.0000 - root_mean_squared_error: 6876.7129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21110/21110 [==============================] - 76s 4ms/step - loss: 47286896.0000 - root_mean_squared_error: 6876.5469\n",
            "Epoch 3/3\n",
            " 6019/21110 [=======>......................] - ETA: 56s - loss: 38907172.0000 - root_mean_squared_error: 6237.5615"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# model1 = load_model('model1/')"
      ],
      "metadata": {
        "id": "8PnNEcA-cI3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_predictions = model1.predict(X_train).flatten()\n",
        "# train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train})\n",
        "# train_results"
      ],
      "metadata": {
        "id": "nBZRBhgJcKLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_predictions = model1.predict(X_test).flatten()\n",
        "# test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test})\n",
        "# test_results\n"
      ],
      "metadata": {
        "id": "SDPdzTcfd31O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def feedforward(models: [], x):\n",
        "    \n",
        "#     output = torch.tensor(x).float()\n",
        "\n",
        "#     for model in models:\n",
        "#         output1 = model(output)\n",
        "#         output = output1\n",
        "        \n",
        "#     return output"
      ],
      "metadata": {
        "id": "nOgGJwax9quv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test in new_test:\n",
        "    exist = False\n",
        "    for train in new_train:\n",
        "        if train == test:\n",
        "            exist = True\n",
        "    \n",
        "    if not exist:\n",
        "        new_test = new_test.drop([test], axis=1)\n",
        "\n",
        "print(len(new_test.dtypes))\n",
        "print(len(new_train.dtypes)-1) # beacause Sales is y data"
      ],
      "metadata": {
        "id": "ZsCO3wom863d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanup3 = {\"StateHoliday\": {\"a\":0, \"b\":1, \"c\":2}}\n",
        "new_test.replace(cleanup3, inplace=True)\n",
        "new_test['StateHoliday'] = new_test['StateHoliday'].astype(int)"
      ],
      "metadata": {
        "id": "uJmOATxU88yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# def feedforward(model1, X_test):\n",
        "    \n",
        "#     output = tf.cast(\n",
        "#     x, float, name=None\n",
        "# )\n",
        "\n",
        "#     for i in model1:\n",
        "#         output1 = model1(output)\n",
        "#         output = output1\n",
        "        \n",
        "#     return output"
      ],
      "metadata": {
        "id": "rsB0LoQ6DJ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_test.reshape((35104,1, 19)\n",
        "# )"
      ],
      "metadata": {
        "id": "vTXpTK4lEyew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = new_test.to_numpy()\n",
        "test = test.reshape((35104,1, 19)\n",
        ")\n",
        "test.shape"
      ],
      "metadata": {
        "id": "mmMmAeXXE-B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test = test.flatten()\n"
      ],
      "metadata": {
        "id": "Da7TbDKoFrcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test = new_test.to_numpy()\n",
        "target = model1.predict(test).flatten()\n",
        "# arr = target.data.cpu().numpy()\n",
        "arr = target\n",
        "prediction_data = pd.DataFrame(arr)\n",
        "prediction_data"
      ],
      "metadata": {
        "id": "GMA4feJjAmJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output = pd.DataFrame({'Id': test, 'Sales': prediction_data[0]})\n",
        "# output.fillna(0, inplace=True)\n",
        "# output.to_csv('submission.csv', index=False)\n",
        "# output"
      ],
      "metadata": {
        "id": "8dOk7qeW5Roy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test = new_test.to_numpy()\n",
        "# target = feedforward(models, test)\n",
        "# arr = target.data.cpu().numpy()\n",
        "# prediction_data = pd.DataFrame(arr)\n",
        "# prediction_data"
      ],
      "metadata": {
        "id": "ZoDqOlu38x0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_results['Actuals'].median()"
      ],
      "metadata": {
        "id": "JS4GVExTfLLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_results['Test Predictions'].mean()"
      ],
      "metadata": {
        "id": "TjGkHJigfaxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test = new_test.to_numpy()\n",
        "# y = feedforward(models, test)\n",
        "# arr = y.data.cpu().numpy()\n",
        "# prediction_data = pd.DataFrame(arr)\n",
        "# prediction_data"
      ],
      "metadata": {
        "id": "KkQdube3cy7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output = pd.DataFrame({'Id': test_data.Id, 'Sales': prediction_data[0]})\n",
        "# output.fillna(0, inplace=True)\n",
        "# output.to_csv('submission.csv', index=False)\n",
        "# output\n"
      ],
      "metadata": {
        "id": "YdqcpL53c2D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM ATTEMPT 1\n"
      ],
      "metadata": {
        "id": "LmgR1aEta_KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Imports\n",
        "# import torch\n",
        "# import torchvision  # torch package for vision related things\n",
        "# import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "# import torchvision.datasets as datasets  # Standard datasets\n",
        "# import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "# from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "# from torch import nn  # All neural network modules\n",
        "# from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "# from tqdm import tqdm  # For a nice progress bar!\n",
        "\n",
        "# # Set device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Hyperparameters\n",
        "# input_size = 28\n",
        "# hidden_size = 256\n",
        "# num_layers = 2\n",
        "# num_classes = 10\n",
        "# sequence_length = 28\n",
        "# learning_rate = 0.0001\n",
        "# batch_size = 64\n",
        "# num_epochs = 2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WldVmO-YW1fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Recurrent neural network (many-to-one)\n",
        "# class RNN(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "#         super(RNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.num_layers = num_layers\n",
        "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "#         self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Set initial hidden and cell states\n",
        "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "#         # Forward propagate LSTM\n",
        "#         out, _ = self.rnn(x, h0)\n",
        "#         out = out.reshape(out.shape[0], -1)\n",
        "\n",
        "#         # Decode the hidden state of the last time step\n",
        "#         out = self.fc(out)\n",
        "#         return out"
      ],
      "metadata": {
        "id": "DevcKCzcW46X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Data\n",
        "# train_dataset = x\n",
        "# test_dataset = y\n",
        "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# # Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM)\n",
        "# model = RNN(input_size, hidden_size, num_layers, num_classes).to(device) # Need to change to RNN if using RNN\n",
        "\n",
        "# # Loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # Train Network\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "#         # Get data to cuda if possible\n",
        "#         data = data.to(device=device).squeeze(1)\n",
        "#         targets = targets.to(device=device)\n",
        "\n",
        "#         # forward\n",
        "#         scores = model(data)\n",
        "#         loss = criterion(scores, targets)\n",
        "\n",
        "#         # backward\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "\n",
        "#         # gradient descent update step/adam step\n",
        "#         optimizer.step()\n",
        "\n",
        "# # Check accuracy on training & test to see how good our model\n",
        "# def check_accuracy(loader, model):\n",
        "#     num_correct = 0\n",
        "#     num_samples = 0\n",
        "\n",
        "#     # Set model to eval\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for x, y in loader:\n",
        "#             x = x.to(device=device).squeeze(1)\n",
        "#             y = y.to(device=device)\n",
        "\n",
        "#             scores = model(x)\n",
        "#             _, predictions = scores.max(1)\n",
        "#             num_correct += (predictions == y).sum()\n",
        "#             num_samples += predictions.size(0)\n",
        "\n",
        "#     # Toggle model back to train\n",
        "#     model.train()\n",
        "#     return num_correct / num_samples\n",
        "\n",
        "\n",
        "# print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
        "# print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "metadata": {
        "id": "GFxWdagYW_xv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}